# Stats-ML-Foundations


![Welcome Image](images/clark-tibbs-oqStl2L5oxI-unsplash.jpg)

Welcome to the course! 

# Dates and Times

Dates: Jan 7–17, 2025 (Tues–Fri of each week) Time: 5:00–8:00 PM (3×50-minute segments per day with 10-minute breaks)
Class URL: https://JHUBlueJays.zoom.us/my/adaraie

# Description

This course provides a solid foundation in probability, statistical inference, and modeling techniques, culminating in modern machine learning and neural network approaches. Lectures will use biological and neural examples but will also be relevant to a broad range of natural sciences. We’ll blend conceptual explanations with demos and hands-on exercises, ensuring that students can practically apply these tools to brain data and other real-world datasets. This 8-day, intensive course will guide participants from foundational probability and inference concepts to the cutting edge of neural networks and transformers, with direct applications to brain research and other natural science domains. By the end, students will be equipped to analyze real neural data, build basic machine learning models, and understand the key building blocks of modern deep learning.

# Instructor & Contact

Instructor: Amir Hossein Daraie Office Hours: By appointment or T/Th after class (9:00–10:45 PM) Contact: adaraie1@jh.edu (mailto:adaraie1@jh.edu)

# Prerequisites

Basic knowledge of algebra and calculus Some familiarity with programming (R or Python) is beneficial but not required

# Learning Outcomes

By the end of this course, students will be able to:

1. Describe and apply fundamental probability distributions used in scientific data analysis.

2. Perform hypothesis testing, calculate and interpret p-values, and avoid common pitfalls (e.g., p-hacking).

3. Understand and implement regression methods (linear, multiple) using software tools.

4. Apply maximum likelihood estimation to fit models to data.

5. Explain key machine learning metrics (confusion matrix, ROC/AUC) and basic ML workflows (cross-validation). 6. Comprehend the core concepts behind neural networks, from backpropagation to CNNs, RNNs, and transformers.

7. Experiment with basic implementations of these methods in R or Python (PyTorch/Lightning), relevant to neural data and other scientific fields.

# Class Schedule

## Day 1: Foundations of Probability, Distributions, and Basic Descriptive Statistics