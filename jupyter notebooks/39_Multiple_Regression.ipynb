{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multiple Regression, Clearly Explained!!!\n",
    "\n",
    "In this notebook, we are going to explore the concept of multiple regression. This is a continuation from the simple linear regression. If you haven't checked the simple linear regression notebook, please do as it forms a basis for this.\n",
    "\n",
    "Just like simple linear regression where we fit a line to the data, multiple regression involves fitting a plane or some higher-dimensional object to your data. When we say higher-dimensional object, we simply mean that we are adding additional data to the model. The 'additional data' can be additional features in our dataset.\n",
    "\n",
    "Let's dive in and see how it works.\n",
    "\n",
    "## Libraries\n",
    "We will use numpy for computations, pandas for data manipulation and matplotlib and seaborn for data visualization. Statsmodel library will be used for building our model.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "```\n",
    "\n",
    "## Load the Data\n",
    "```python\n",
    "data = pd.read_csv('data.csv')\n",
    "```\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "```python\n",
    "data.head()\n",
    "```\n",
    "\n",
    "## Fit the Model\n",
    "We will use the statsmodels library to fit our multiple regression model. In this example, we will be predicting body length using mouse weight and tail length. If we had additional factors like the amount of food eaten or the amount of time spent running on a wheel, we would also consider them in our model.\n",
    "\n",
    "```python\n",
    "model = ols('body_length ~ mouse_weight + tail_length', data=data).fit()\n",
    "```\n",
    "\n",
    "## Model Summary\n",
    "```python\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "In the model summary, we are interested in the R-squared value and the p-value. The R-squared value tells us how well our line fits the data while the p-value gives us the significance of our model.\n",
    "\n",
    "In multiple regression, we adjust the R-squared to compensate for the additional parameters in the equation. The formula for R-squared is given by:\n",
    "\n",
    "$$R^2 = \\frac{SS_{fit}}{SS_{mean}}$$\n",
    "\n",
    "where $SS_{fit}$ is the sum of squares around the fit and $SS_{mean}$ is the sum of squares around the mean value for the body length.\n",
    "\n",
    "We can also calculate a p-value for our R-squared. The formula for p-value is given by:\n",
    "\n",
    "$$F = \\frac{(SS_{fit}/P_{fit})}{(SS_{mean}/P_{mean})}$$\n",
    "\n",
    "where $P_{fit}$ is the number of parameters in the equation that the least-squares have to estimate and $P_{mean}$ is the number of parameters for estimating the mean value of the body length. In this case, $P_{mean}$ will always be 1.\n",
    "\n",
    "We can also compare the simple regression model and the multiple regression model. This is helpful in determining whether the additional data (features) are worth considering in our model. The formula is similar to that of p-value only that we replace the mean values with the simple regression values.\n",
    "\n",
    "$$F = \\frac{(SS_{multi}/P_{multi})}{(SS_{simple}/P_{simple})}$$\n",
    "\n",
    "where $SS_{multi}$ and $P_{multi}$ are the sum of squares and number of parameters for the multiple regression and $SS_{simple}$ and $P_{simple}$ are the sum of squares and number of parameters for the simple regression.\n",
    "\n",
    "If the difference in R-squared values between the simple and multiple regression is big and the p-value is small then adding the additional data to the model is worth the trouble.\n",
    "\n",
    "Multiple regression is a powerful tool that allows us to predict the value of a variable based on the values of two or more other variables. It's an extension of simple linear regression that allows for predictions with greater accuracy and precision.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "In this notebook, we have seen how to do multiple regression and how to evaluate our model using R-squared and p-value. We have also seen how to compare a simple regression model and a multiple regression model. In the next notebook, we will see how to do multiple regression in R. Stay tuned!!!\n",
    "\n",
    "## References\n",
    "1. James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning (Vol. 112, p. 18). New York: springer.\n",
    "2. Kutner, M. H., Nachtsheim, C. J., & Neter, J. (2004). Applied linear regression models (4th ed) (No. 04; QA278, .K8 2004.).\n",
    "3. Montgomery, D. C., Peck, E. A., & Vining, G. G. (2012). Introduction to linear regression analysis (Vol. 821). John Wiley & Sons.\n",
    "4. [StatQuest: Multiple Regression](https://www.youtube.com/watch?v=1hbCJyM9ccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "np.random.seed(42)\n",
    "X1 = np.random.rand(100) * 10  # Feature 1\n",
    "X2 = np.random.rand(100) * 10  # Feature 2\n",
    "y = 3 * X1 + 2 * X2 + np.random.randn(100) * 2  # Target with noise\n",
    "\n",
    "# Combine X1 and X2 into a feature matrix\n",
    "X = np.column_stack((X1, X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -0.17877992709985335\n",
      "Coefficients: [2.93165494 2.14386228]\n"
     ]
    }
   ],
   "source": [
    "# Fit a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print coefficients\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Coefficients:\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 19:49:19.559 python[757:15827619] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-10 19:49:19.559 python[757:15827619] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "2025-01-10 19:51:24.109 python[757:15827619] _TIPropertyValueIsValid called with 16 on nil context!\n",
      "2025-01-10 19:51:24.109 python[757:15827619] imkxpc_getApplicationProperty:reply: called with incorrect property value 16, bailing.\n",
      "2025-01-10 19:51:24.109 python[757:15827619] Text input context does not respond to _valueForTIProperty:\n"
     ]
    }
   ],
   "source": [
    "# Create a grid for visualization\n",
    "X1_grid, X2_grid = np.meshgrid(np.linspace(0, 10, 30), np.linspace(0, 10, 30))\n",
    "y_pred_grid = (model.intercept_ +\n",
    "               model.coef_[0] * X1_grid +\n",
    "               model.coef_[1] * X2_grid)\n",
    "\n",
    "# Plot the data points and regression plane\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X1, X2, y, color='blue', label='Data points')\n",
    "ax.plot_surface(X1_grid, X2_grid, y_pred_grid, alpha=0.5, color='orange', label='Regression plane')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('Feature 1 (X1)')\n",
    "ax.set_ylabel('Feature 2 (X2)')\n",
    "ax.set_zlabel('Target (y)')\n",
    "ax.set_title('3D Visualization of Multiple Regression')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}