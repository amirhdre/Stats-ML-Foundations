{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bee0ec",
   "metadata": {},
   "source": [
    "\n",
    "# The SoftMax Derivative, Step-by-Step!!!\n",
    "\n",
    "This notebook explains the SoftMax derivative step-by-step, inspired by the StatQuest video. The SoftMax function is fundamental in machine learning for converting logits to probabilities, and understanding its derivative is key for model optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244b51a3",
   "metadata": {},
   "source": [
    "\n",
    "## SoftMax Function\n",
    "\n",
    "The SoftMax function for a vector $ z = [z_1, z_2, \\ldots, z_k] $ is defined as:\n",
    "\n",
    "$$\n",
    "\\sigma(z_i) = \n",
    "\\frac{e^{z_i}}{\\sum_{j=1}^k e^{z_j}}\n",
    "$$\n",
    "\n",
    "It normalizes logits into a probability distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891521ea",
   "metadata": {},
   "source": [
    "\n",
    "## Derivatives of the SoftMax Function\n",
    "\n",
    "### Case 1: \n",
    "$\\frac{\\partial \\sigma(z_i)}{\\partial z_i} $ (when \\( i = k \\))\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\sigma(z_i)}{\\partial z_i} = \\sigma(z_i) (1 - \\sigma(z_i))\n",
    "$$\n",
    "\n",
    "### Case 2:\n",
    "$\\frac{\\partial \\sigma(z_i)}{\\partial z_k}$ (when \\( i \n",
    "eq k \\))\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\sigma(z_i)}{\\partial z_k} = -\\sigma(z_i) \\cdot \\sigma(z_k)\n",
    "$$\n",
    "\n",
    "The derivative can be represented as the Jacobian matrix of the SoftMax function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b74a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Compute the SoftMax of a vector z.\n",
    "    \"\"\"\n",
    "    exp_z = np.exp(z - np.max(z))  # Numerical stability\n",
    "    return exp_z / np.sum(exp_z)\n",
    "\n",
    "def softmax_derivative(softmax_probs):\n",
    "    \"\"\"\n",
    "    Compute the Jacobian matrix of the SoftMax function.\n",
    "    \"\"\"\n",
    "    n = len(softmax_probs)\n",
    "    jacobian = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                jacobian[i][j] = softmax_probs[i] * (1 - softmax_probs[i])\n",
    "            else:\n",
    "                jacobian[i][j] = -softmax_probs[i] * softmax_probs[j]\n",
    "    return jacobian\n",
    "\n",
    "# Example usage\n",
    "z = np.array([1.0, 2.0, 3.0])  # Example logits\n",
    "softmax_probs = softmax(z)\n",
    "jacobian = softmax_derivative(softmax_probs)\n",
    "\n",
    "print(\"SoftMax probabilities:\", softmax_probs)\n",
    "print(\"Jacobian matrix:\", jacobian)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806568a",
   "metadata": {},
   "source": [
    "\n",
    "## Example Calculation\n",
    "\n",
    "Given logits \\( z = [1.0, 2.0, 3.0] \\), the SoftMax probabilities are computed as:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\text{softmax}(z)\n",
    "$$\n",
    "\n",
    "The Jacobian matrix represents the derivatives of each SoftMax probability with respect to all logits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a308c5",
   "metadata": {},
   "source": [
    "\n",
    "## References\n",
    "\n",
    "1. Goodfellow, Ian, et al. *Deep Learning*. MIT Press, 2016.\n",
    "2. [StatQuest YouTube Channel](https://www.youtube.com/@statquest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574595c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2860987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
