{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Comprehensive Visualization of Our CNN Model**\n",
    "\n",
    "In this section, we'll demonstrate how to **visualize our CNN's** architecture and internal details in Python. We'll use:\n",
    "\n",
    "- **Model Summary**: to see a text-based breakdown of each layer, the output shape, and the number of parameters.\n",
    "- **Graph Visualization** (via [**torchviz**](https://github.com/szagoruyko/pytorchviz)): to generate a graphical representation of how data flows through the CNN.\n",
    "\n",
    "## **Requirements**\n",
    "1. `pip install torchviz`\n",
    "2. `pip install torchsummary` or `pip install torch-summary` (depending on your preference)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import and Define the Model (Review)**\n",
    "\n",
    "We'll re-use the same CNN model we built previously for classifying letters (O, X, T, S) in a 10x10 image. If you've already defined your model in the same notebook, you can skip re-defining it here. Otherwise, let's re-define it below for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875539ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (0.0.3)\n",
      "Requirement already satisfied: graphviz in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: torch in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (from torchviz) (2.0.1)\n",
      "Requirement already satisfied: filelock in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (from torch->torchviz) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (from torch->torchviz) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (from torch->torchviz) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (from torch->torchviz) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (from torch->torchviz) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (from jinja2->torch->torchviz) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (from sympy->torch->torchviz) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b93bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /Users/amirhosseindaraie/miniconda3/envs/pytorch_m1/lib/python3.8/site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLetterCNN(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=12, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot\n",
    "\n",
    "class MultiLetterCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(MultiLetterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc = nn.Linear(12 * 1 * 1, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # (batch, 6, 8, 8)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)  # (batch, 6, 4, 4)\n",
    "\n",
    "        x = self.conv2(x)  # (batch, 12, 2, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)  # (batch, 12, 1, 1)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # flatten => (batch, 12)\n",
    "        x = self.fc(x)            # => (batch, 4)\n",
    "        return x\n",
    "\n",
    "# Instantiate a model instance.\n",
    "model = MultiLetterCNN(num_classes=4)\n",
    "model.eval()  # set model to eval mode for consistency\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Model Summary (Text-Based)**\n",
    "\n",
    "The **torchsummary** (or **torch-summary**) package prints a concise table with the following columns:\n",
    "- Layer name\n",
    "- Output shape (N, C, H, W)\n",
    "- Number of parameters\n",
    "\n",
    "If you haven't installed torchsummary, run:\n",
    "```bash\n",
    "!pip install torchsummary\n",
    "```\n",
    "\n",
    "Then we can do the following to get a summary of our model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 6, 8, 8]              60\n",
      "         MaxPool2d-2              [-1, 6, 4, 4]               0\n",
      "            Conv2d-3             [-1, 12, 2, 2]             660\n",
      "         MaxPool2d-4             [-1, 12, 1, 1]               0\n",
      "            Linear-5                    [-1, 4]              52\n",
      "================================================================\n",
      "Total params: 772\n",
      "Trainable params: 772\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# If needed: !pip install torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# We expect input of shape (1, 10, 10) for our single-channel 10x10 images.\n",
    "summary(model, input_size=(1, 10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a table indicating each layer (Conv2d, MaxPool2d, etc.), its output shape, and the total parameters. This allows a quick textual overview of how the data flows through the network.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Graph Visualization with *torchviz***\n",
    "\n",
    "Next, we'll demonstrate a detailed visualization of our network as a graph, showing how each operation is connected. We'll:\n",
    "1. Pass a **dummy input** (random tensor) into the model to capture the computational graph.\n",
    "2. Use **`make_dot`** from `torchviz` to visualize the graph.\n",
    "\n",
    "**Note**: `torchviz` uses [Graphviz](https://graphviz.org/) under the hood. Make sure you have Graphviz installed on your machine as well (e.g., `sudo apt-get install graphviz` on Ubuntu or use an installer on Windows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MultiLetterCNN_Graph.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If needed: !pip install torchviz\n",
    "\n",
    "dummy_input = torch.randn(1, 1, 10, 10)  # (batch_size=1, channels=1, height=10, width=10)\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Create a graphical representation of the model.\n",
    "# We map each parameter name => parameter.\n",
    "dot = make_dot(\n",
    "    output,\n",
    "    params=dict(model.named_parameters()),  # This adds parameter nodes\n",
    "    show_attrs=False,\n",
    "    show_saved=False\n",
    ")\n",
    "\n",
    "# You can render the graph to a file.\n",
    "# For instance, to create a PNG:\n",
    "# dot.render(\"MultiLetterCNN_Graph\", format=\"png\")\n",
    "\n",
    "# Instead, let's display the raw graph in the notebook.\n",
    "# NOTE: Some notebook environments will display an interactive graph\n",
    "# but if it doesn't show inline, you might have to open the file.\n",
    "dot.render(\"MultiLetterCNN_Graph\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c35ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning:\u001b[0m graphviz 12.2.1 is already installed and up-to-date.\n",
      "To reinstall 12.2.1, run:\n",
      "  brew reinstall graphviz\n"
     ]
    }
   ],
   "source": [
    "# !sudo port install graphviz\n",
    "!brew install graphviz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your notebook environment, the graph may appear inline or you might see a link to the `.svg` or `.pdf` file. Clicking on it should open the full network graph. If you have Graphviz properly installed, you can also run:\n",
    "```python\n",
    "dot.render(\"MultiLetterCNN_Graph\", format=\"png\")\n",
    "```\n",
    "and then check your current directory for **`MultiLetterCNN_Graph.png`**, which you can open to see a comprehensive flow diagram of how data travels through your CNN.\n",
    "\n",
    "### **Graph Explanation**\n",
    "- **Blue nodes** typically represent **model parameters** (weights, biases, etc.).\n",
    "- **Orange nodes** represent operations (like convolution, ReLU, pooling, linear, etc.).\n",
    "- **White nodes** represent **tensors** flowing between operations.\n",
    "\n",
    "By examining the graph, you get a detailed, step-by-step visualization of the entire forward pass.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Putting It All Together**\n",
    "\n",
    "Here's a concise recap:\n",
    "1. **Model Summary** gives a quick textual overview of shapes and params.\n",
    "2. **Graph Visualization** (torchviz) provides an in-depth, graphical breakdown of every operation in the network.\n",
    "\n",
    "Together, these tools give a **very comprehensive** understanding of your CNN—both at a high-level (layer-by-layer) and a low-level (tensor flow through the network) perspective.\n",
    "\n",
    "___\n",
    "**Quest on!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f42c72",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fcdbb68",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "name": "Comprehensive_CNN_Visualization.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
