{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d88d62c8",
   "metadata": {},
   "source": [
    "\n",
    "# Neural Networks: Multiple Inputs and Outputs\n",
    "\n",
    "## Overview\n",
    "This lesson focuses on neural networks with multiple inputs and outputs. We'll explore how they work and how the weights, biases, and activation functions create \"crinkled surfaces\" for predictions.\n",
    "\n",
    "## Single Input and Output\n",
    "- **Input:** $x$ (e.g., drug dosage).\n",
    "- **Output:** $y$ (e.g., drug effectiveness).\n",
    "- The graph is 2D: input on $x$-axis, output on $y$-axis.\n",
    "- Activation functions (e.g., ReLU) modify the input-output relationship.\n",
    "\n",
    "### Key Equations:\n",
    "1. Weighted input: $z = w \\cdot x + b$\n",
    "2. ReLU activation: $a = \\max(0, z)$\n",
    "\n",
    "## Multiple Inputs and Outputs\n",
    "### Example: Predicting Iris Species\n",
    "- Inputs: Petal width ($p$), Sepal width ($s$).\n",
    "- Outputs: Probabilities for species Setosa, Versicolor, Virginica.\n",
    "\n",
    "### Network Architecture\n",
    "1. **Inputs:** Two nodes for $p$ and $s$.\n",
    "2. **Hidden Layer:** Each node computes:\n",
    "   $$z = w_p \\cdot p + w_s \\cdot s + b$$\n",
    "   $$a = \\max(0, z)$$\n",
    "3. **Outputs:** Three nodes for species probabilities.\n",
    "\n",
    "### Surface Creation\n",
    "1. For each output node, calculate weights and biases for hidden layer connections.\n",
    "2. Compute weighted sums and biases.\n",
    "3. Apply ReLU activation to generate bent surfaces.\n",
    "4. Combine surfaces for final predictions.\n",
    "\n",
    "## Practical Example\n",
    "1. Input scaled values ($p, s$ between 0 and 1).\n",
    "2. Compute intermediate activations for hidden layer nodes.\n",
    "3. Generate crinkled surfaces for each species.\n",
    "4. Use final output values to predict species.\n",
    "\n",
    "### Equations Recap:\n",
    "- **Weighted sum:** $z = w_p \\cdot p + w_s \\cdot s + b$\n",
    "- **ReLU:** $a = \\max(0, z)$\n",
    "- **Output:** $y = a \\cdot w + b_{out}$\n",
    "\n",
    "## Visualizing Outputs\n",
    "- Each species prediction corresponds to a \"crinkled surface.\"\n",
    "- Higher values on the surface indicate stronger predictions.\n",
    "\n",
    "## Final Prediction\n",
    "- Use softmax or argmax to determine the most probable output.\n",
    "\n",
    "## Conclusion\n",
    "Neural networks with multiple inputs and outputs use weights, biases, and activation functions to model complex relationships. By combining intermediate calculations, they predict outputs effectively, even for multi-class problems.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}