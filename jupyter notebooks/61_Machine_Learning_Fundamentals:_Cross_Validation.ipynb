{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning Fundamentals: Cross Validation\n",
        "\n",
        "Cross Validation is a pivotal step in the machine learning pipeline. It helps us understand how well our model will generalize to unseen data. In this notebook, we will dive deep into understanding and implementing Cross Validation. \n",
        "\n",
        "![Cross Validation](https://miro.medium.com/max/1200/1*rgba1BIOUys7wQcXcL4U5A.png)\n",
        "\n",
        "_Image Source: [Medium](https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f)_\n",
        "\n",
        "So let's start by importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Data\n",
        "\n",
        "For the purpose of this demonstration, we will be using the Iris dataset which is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems. It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. The data set consists of 50 samples from each of three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured from each sample: the lengths and the widths of the sepals and petals, in centimeters.\n",
        "\n",
        "Let's load the data and understand it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementing Cross Validation\n",
        "\n",
        "Now let's implement a basic train-test split and apply Cross Validation on it. We will start with 5 fold cross validation and we will use three different models (Logistic Regression, K Nearest Neighbors and Support Vector Machines) for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "models = [logreg, knn, svm]\n",
        "model_names = ['Logistic Regression', 'K Nearest Neighbors', 'Support Vector Machines']\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    cv_score = cross_val_score(model, X_train, y_train, cv=5)\n",
        "    print(f'{model_names[i]} Average Score: {np.mean(cv_score)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above output, we can observe that all three models perform well on the Iris dataset. We can select the model with the highest Cross-Validation score.\n",
        "\n",
        "## Understanding the number of folds\n",
        "\n",
        "In the above example, we used a 5-fold cross-validation. However, the number of folds is arbitrary and can be tuned. In an extreme case, we could call each individual data point a block. This is called \"Leave One Out Cross Validation\". Each sample is tested individually. That said in practice it is very common to divide the data into ten blocks. This is called 10-fold cross-validation.\n",
        "\n",
        "## Tuning Parameters using Cross Validation\n",
        "\n",
        "Cross Validation can also be used to tune the hyperparameters of our model. We can use GridSearchCV or RandomizedSearchCV to tune our hyperparameters using Cross Validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "1. [StatQuest: Cross Validation, Clearly Explained](https://www.youtube.com/watch?v=fSytzGwwBVw)\n",
        "2. [Cross-validation: evaluating estimator performance](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
        "3. [Wikipedia: Cross-validation (statistics)](https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n",
        "4. [Cross Validation in Machine Learning](https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
